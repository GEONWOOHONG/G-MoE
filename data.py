# data.py â€” ë°ì´í„°ì…‹ ë¡œë“œ ìœ í‹¸
import os, random, numpy as np, torch
from datasets import load_dataset
from datasets.utils import logging as ds_logging

def _is_rank0():
    return int(os.environ.get("RANK", "0")) == 0

def worker_init_fn(worker_id):
    """ì›Œì»¤ ì‹œë“œ ê³ ì •ì„ ìœ„í•œ ì´ˆê¸°í™” í•¨ìˆ˜"""
    # ë¶„ì‚° í™˜ê²½ì—ì„œ rank ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    rank = 0
    if "RANK" in os.environ:
        rank = int(os.environ["RANK"])
    
    # ê° ì›Œì»¤ë§ˆë‹¤ ê³ ìœ í•œ ì‹œë“œ ì„¤ì •
    worker_seed = 42 + worker_id + rank
    torch.manual_seed(worker_seed)
    np.random.seed(worker_seed)
    random.seed(worker_seed)

def get_dataloader_generator(rank=0):
    """DataLoaderìš© Generator ìƒì„±"""
    g = torch.Generator()
    g.manual_seed(42 + rank)
    return g

def load_or_prepare_pile(cache_path=None, raw_cache=None, verbose=True):
    """
    HF datasets ë¡œë“œ (ë¶„ì‚° ì•ˆì „)
    - verbose=False ë©´ ì–´ë–¤ ë­í¬ë“  ë©”ì‹œì§€ ìµœëŒ€í•œ ì–µì œ
    - verbose=True ë©´ rank0ë§Œ ìµœì†Œ ë©”ì‹œì§€ ì¶œë ¥
    """
    cache_dir = os.environ.get("HF_DATASETS_CACHE", None)

    # â˜† ë¹„-rank0 ë˜ëŠ” verbose=False ë©´ í”„ë¡œê·¸ë ˆìŠ¤ë°”/ë¡œê·¸ ì–µì œ
    if (not _is_rank0()) or (not verbose):
        try:
            ds_logging.set_verbosity_error()
            ds_logging.disable_progress_bar()
        except Exception:
            pass  # êµ¬ë²„ì „ í˜¸í™˜

    if verbose and _is_rank0():
        print(f"ğŸ”¹ Loading Geonwoohong/pile-uncopyrighted-6b-tokenized-gpt2 (cache_dir={cache_dir})")

    ds = load_dataset(
        "Geonwoohong/pile-uncopyrighted-6b-tokenized-gpt2",
        cache_dir=cache_dir
    )
    return ds["train"], ds["validation"]